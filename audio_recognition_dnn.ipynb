{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "%matplotlib inline\n",
    "import re\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read each wav file convert into a spectogram and flatten it as x\n",
    "# read and the corresponding label and convert into one hot encoding as Y\n",
    "# Baseline : Start with DNN classifier with  two hidden layesr and drop out as regularization at each step\n",
    "# output layer  10 neurons for classification at output.\n",
    "# Once the wave forms are converted, its akin to image comparison \n",
    "# MLP Model can be like a baseline.\n",
    "# we will have to compare against performance using  CNNs , and also AUTOENCODERS.\n",
    "\n",
    "#TODO - Use confusion matrix and validate how confused are the classification.\n",
    "#TODO - remove any outliers in data input. \n",
    "\n",
    "AUDIO_PATH = 'Documents/data_speech_commands_v0.02/'\n",
    "LABELS = ['eight', 'five', 'four', 'one',  'seven', 'six', 'three', 'two', 'zero', 'nine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original sound wav - we cant use as its highly random wav and difficult to identify pattern\n",
    "#Many options - convert to spectogram / or more advanced : Mel-frequency cepstral coefficients (MFCCs) \n",
    "#current implementation is for spectogram .\n",
    "\n",
    "#convert into spectograms : look at how the actual wav form it is \n",
    "\n",
    "sample_rate1, samples1 = wavfile.read(str(AUDIO_PATH) + '/zero/0a2b400e_nohash_0.wav')\n",
    "sample_rate2, samples2 = wavfile.read(str(AUDIO_PATH) + '/one/0a2b400e_nohash_0.wav')\n",
    "sample_rate3, samples3 = wavfile.read(str(AUDIO_PATH) + '/two/0a2b400e_nohash_0.wav')\n",
    "frequencies1, times1, spectogram1 = signal.spectrogram(samples1, sample_rate1)\n",
    "frequencies2, times2, spectogram2 = signal.spectrogram(samples2, sample_rate2)\n",
    "frequencies3, times3, spectogram3 = signal.spectrogram(samples3, sample_rate3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2457eda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20,20))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Spectogram - zero')\n",
    "ax1.imshow(spectogram1)\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Spectogram - one')\n",
    "ax2.imshow(spectogram2)\n",
    "\n",
    "ax2 = fig.add_subplot(313)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Spectogram - two')\n",
    "ax2.imshow(spectogram3)\n",
    "\n",
    "#OBSERVATION : \n",
    "#Can see that half the time series is with silence and the clippings could be clipped for dimension reduction\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files with only (0 -9) for simplicity, \n",
    "# lets neglect other wav files .\n",
    "# TODO  add more classification such as silence, unknown for other input waves.\n",
    "# DATASET USED \n",
    "# https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data\n",
    "#data set downloaded locally  under relative path /Documents/data_speech_commands_vo.02\n",
    "\n",
    "\n",
    "# for each label , read the training and validation files and corresponding target label \n",
    "def create_list_of_validation_files():\n",
    "\n",
    "    fp = open(AUDIO_PATH + \"validation_list.txt\", 'r')\n",
    "    line = fp.readline()\n",
    "    cnt = 1\n",
    "    validation_file_list =[]\n",
    "    while line:\n",
    "       validation_file_list.append(line.strip())\n",
    "       line = fp.readline()\n",
    "    return validation_file_list\n",
    "\n",
    "\n",
    "#CREATE INPUT TRAIN AND VALIDATION DATA SET\n",
    "#TODO - DIMENSION REDUCTION BY CLIPPING SILENCE( can see more shorter clips)\n",
    "#TODO - DIMENSION REDUCTION BY Resampling \n",
    "#TODO - DATA AUGMENTATION BY ADDING NOISE AND CREATE NEW SOUND CLIPS \n",
    "\n",
    "def create_input(validation_file_list):\n",
    "\n",
    "    filecount = 0\n",
    "    wavefiles = []\n",
    "    #using lists instead of numpy array for faster reading while loop \n",
    "    X_train = []\n",
    "    X_validation = []\n",
    "    y_train= []\n",
    "    y_validation = []\n",
    "    for  label in LABELS:\n",
    "        #read each file under train_label and convert it into histogram assign to first ,\n",
    "        #assign label \n",
    "        wavefile = glob.glob(AUDIO_PATH  + label + \"/*.wav\")\n",
    "        for wav in wavefile:\n",
    "            sample_rate, samples = wavfile.read(wav)\n",
    "            frequencies, times, spectogram = signal.spectrogram(samples, sample_rate)\n",
    "            filename = re.split(AUDIO_PATH , wav)\n",
    "            if(len(times)==71): \n",
    "                #currently reading only similar length file\n",
    "                #TODO IMPROVE BY PADDING IF FILE LENGTH IS LESS OR CLIP IF MORE \n",
    "                try:\n",
    "                    if(filename[1] in validation_file_list): \n",
    "                        X_validation.append(np.array(spectogram))\n",
    "                        y_validation.append(label)\n",
    "                    else:\n",
    "                        X_train.append(np.array(spectogram))\n",
    "                        y_train.append(label)\n",
    "                except:\n",
    "                     pass \n",
    "    return X_train, y_train,X_validation, y_validation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list = create_list_of_validation_files()\n",
    "# get all the files that needs to be in validation test data set, so we can correctly split the wav forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32293 32293 3338 3338\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_validation, y_validation = create_input(validation_list)\n",
    "print(len(X_train), len(y_train), len(X_validation), len(y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_Train = np.asarray(X_train)\n",
    "y_Train = np.asarray(y_train)\n",
    "X_Validation = np.asarray(X_validation)\n",
    "y_Validation = np.asarray(y_validation)\n",
    "\n",
    "\n",
    "# FIRST LABEL ENCODE AND ONE HOT ENCODE FOR CATEGORICAL OUTPUT TO FEED TO NEURAL NW\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_Train)\n",
    "y_Train = label_encoder.transform(y_Train.reshape(-1,1))\n",
    "y_Validation = label_encoder.transform(y_Validation.reshape(-1,1))\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_Train = onehot_encoder.fit_transform(y_Train.reshape(-1,1))\n",
    "y_Validation = onehot_encoder.transform(y_Validation.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLATTEN INPUT ARRAYS\n",
    "X_Train = X_Train.reshape(32293, 129*71)\n",
    "X_Validation = X_Validation.reshape(3338, 129*71)\n",
    " INPUT_SHAPE = 129*71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.02585 16.335938\n",
      "0.0 1.0000001\n"
     ]
    }
   ],
   "source": [
    "#normalize inputs, we take log of values to have much reasonable scale between frequencies\n",
    "# check for other custom built libraries which could do logarithmic transform to give more weightage to frequency range of interest\n",
    "\n",
    "X_Train = np.log(X_Train+ 1e-10) # add small error to avoid  infinity. \n",
    "print(np.min(X_Train), np.max(X_Train))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_Train = MinMaxScaler().fit_transform(X_Train)\n",
    "print(np.min(X_Train), np.max(X_Train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               4689920   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,756,874\n",
      "Trainable params: 4,756,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32293 samples, validate on 3338 samples\n",
      "Epoch 1/20\n",
      "32293/32293 [==============================] - 172s 5ms/step - loss: 2.3139 - acc: 0.1030 - val_loss: 6.7595 - val_acc: 0.1111\n",
      "Epoch 2/20\n",
      "32293/32293 [==============================] - 190s 6ms/step - loss: 2.3034 - acc: 0.1036 - val_loss: 3.9552 - val_acc: 0.1058\n",
      "Epoch 3/20\n",
      "32293/32293 [==============================] - 194s 6ms/step - loss: 2.3030 - acc: 0.1041 - val_loss: 3.2452 - val_acc: 0.1090\n",
      "Epoch 4/20\n",
      "32293/32293 [==============================] - 193s 6ms/step - loss: 2.3026 - acc: 0.1038 - val_loss: 2.6563 - val_acc: 0.1072\n",
      "Epoch 5/20\n",
      "32293/32293 [==============================] - 205s 6ms/step - loss: 2.3028 - acc: 0.1053 - val_loss: 2.5140 - val_acc: 0.1007\n",
      "Epoch 6/20\n",
      "32293/32293 [==============================] - 204s 6ms/step - loss: 2.3036 - acc: 0.1009 - val_loss: 2.3190 - val_acc: 0.1055\n",
      "Epoch 7/20\n",
      " 2112/32293 [>.............................] - ETA: 3:25 - loss: 2.3035 - acc: 0.1089"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "EPOCHS = 20 # ideally need to run for longer epoch \n",
    "BATCHSIZE = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,  kernel_initializer='TruncatedNormal',activation='relu', input_shape=(INPUT_SHAPE,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,  kernel_initializer='TruncatedNormal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, kernel_initializer='TruncatedNormal', activation='softmax')) \n",
    "#SINCE WE WANT OUTPUT TO BE PROBABILITY OF PREDICTION TO PARTICULAR CLASS, use softmax activation at output\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', # ITS CLASSIFICATION PROBLEM \n",
    "              optimizer='adam', # CAN VARY OPTIMIZER for baseline , adam is selected.  \n",
    "              metrics=['accuracy']) # TODO check for confidence ( probablity of top three prediction class difference etc) \n",
    "\n",
    "history = model.fit(X_Train, y_Train,\n",
    "                    batch_size=BATCHSIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_Validation, y_Validation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
